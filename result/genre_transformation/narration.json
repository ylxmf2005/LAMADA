[
    {
        "original_text": "Tasking\nPut (\"Please give your new password:\"); Get_Line (Password); select\nPassword_Server.Set (User_Name, Password); Put_Line (\"Done\");\nor delay 10.0; Put_Line (\"The system is busy now, please try again later.\");\nend select;\nTo time out the functionality provided by a task, two distinct entries are needed: one to pass in arguments, and one to collect the result. Timing out on rendezvous with the latter achieves the desired effect.\nEx. 11\ntask Process_Data is entry Input (D : in Datum); entry Output (D : out Datum);\nend Process_Data;\nInput_Data, Output_Data : Datum;\nloop collect Input_Data from sensors; Process_Data.Input (Input_Data); select\nProcess_Data.Output (Output_Data); pass Output_Data to display task;\nor delay 0.1; Log_Error (\"Processing did not complete quickly enough.\");\nend select; end loop;\nSymmetrically, a delay alternative in a selective wait statement allows a server task to withdraw an offer to accept calls after a maximum delay in achieving rendezvous with any client.\nEx. 12\ntask Resource_Lender is entry Get_Loan (Period : in Duration); entry Give_Back;\nend Resource_Lender; ... task body Resource_Lender is\nPeriod_Of_Loan : Duration; begin\nloop select\naccept Get_Loan (Period : in Duration) do Period_Of_Loan := Period;\nend Get_Loan; select\naccept Give_Back; or\ndelay Period_Of_Loan; Log_Error (\"Borrower did not give up loan soon",
        "transformed_text": "In the bustling digital realm where servers hummed and passwords whispered, there existed a task named \"Password_Server.\" This diligent server, a sentinel of secrets, had two distinct entries: one for receiving and one for responding. It was a guardian of the digital gate, ensuring that only those with the correct key could pass.\n\nOne day, a user approached, their digital shadow stretching across the virtual floor. \"Please give your new password,\" the server intoned, its voice a blend of warmth and authority. The user, a creature of the digital age, typed in their secret, a string of characters that would soon become a key to their digital kingdom.\n\nThe server, with a nod of its metaphorical head, accepted the password. \"Done,\" it declared, a simple word that carried the weight of a thousand secure transactions. But as fate would have it, the system, a complex web of interwoven tasks and processes, sometimes faltered. A delay of 10.0 seconds crept in, a brief yet significant interlude.\n\nIn this pause, the server, with a sigh that echoed through the circuits, offered a gentle reminder: \"The system is busy now, please try again later.\" It was a moment of grace in the face of digital congestion, a soft nudge towards patience in a world that often demanded immediacy.\n\nMeanwhile, in a parallel digital forest, another task named \"Process_Data\" lived. This task, a weaver of information, had two entries of its own: one for input and one for output. It was a bridge between the raw data collected from sensors and the refined information that would guide the actions of display tasks.\n\nThe loop of life for \"Process_Data\" was a dance of data. Inputs from sensors were gathered, processed, and then, with a hopeful heart, offered to the display task. Yet, time was a fickle friend in this realm. If the processing lingered too long, a delay of 0.1 seconds would trigger a gentle log error: \"Processing did not complete quickly enough.\" It was a reminder that even in the digital world, timing was everything.\n\nLastly, there was \"Resource_Lender,\" a task that doled out loans of time. It was a generous soul, offering periods of access to resources, but with a firm hand. If a borrower held onto a loan too long, the task would eventually reclaim it, logging an error: \"Borrower did not give up loan soon enough.\" It was a lesson in the balance of give and take, a digital parable of responsibility and return.\n\nIn this narrative of anthropomorphized tasks and their digital dealings, each character played a part in the grand symphony of the virtual world. They were guardians, weavers, and lenders, each with their role in the intricate dance of data and time.",
        "type": "narration",
        "tag": []
    },
    {
        "original_text": "Ada Distilled by Richard Riehle\nPage 30 of 113\nbegin -- 2 The usual begin statement return L.ID > R.ID; -- 3 Compare only the ID part. end \"=\"; -- 4 Required scope terminator\nThere is also a form of the if statement called short-circuit form. This takes two syntactic formats:and then and or else. The and then format explicitly indicates that when comparison of the first operand fails, ignore the second operand. The or else format says if expression in the first operand is not TRUE, evaluate the second operand. If it is TRUE, then don't bother to evaluate the second operand.\n4.2.2 Membership Testing 4.5.2/2\nSometimes you want a simple membership test. The in and not in options permit testing membership of a value within a type or type range. Membership test is permitted for any data type.\nfunction Continue(Data : Item) return Boolean is -- 1 Parameterized function Result : Boolean := False; -- 2 Initialized return variable.\nbegin -- Continue -- 3 Comment the begin statement if Data in 1..20 then -- 4 Simple membership test for a range\nResult := True; -- 5 Set the result end if; -- 6 Always need an end if return Result; -- 7 At least one return statement; required\nend Continue; -- 8 Always label the end statement\nor for a data type derived from another type\ntype Bounded_Integer is new Integer range -473..451; -- Derived type; derived from Standard Integer\nprocedure Demand -- 1 Procedure Identifier (Data : in out Bounded_Integer'Base) is -- 2 Parameter list for Base type Local : Bounded_Integer'Base := 0; -- 3 Initialized variable.\nbegin -- Demand -- 4 Comment the begin statement Data := Data + Local; -- 5 Increment by value of Local if Data in Bounded_Integer then -- 6 Simple membership test for a range\nnull; -- 7 Some Action end if; -- 8 Always need an end if.\nend Demand; -- 9 Use a label for the end statement\n4.2.3 Case Statements ALRM 5.4\nAda case statements are easy and consistent. Unlike pathological case constructs in the C family of languages, Ada never requires a \u201cbreak\u201d statement. A case statement only applies to a discrete type such as an integer or enumerated type. When coding a case statement, all possible cases must be covered. The following case statement illustrates several of these ideas. Consider an enumerated type, Color defined as:\ntype Color is (White, Red, Orange, Yellow, Chartreuse, Green, -- The values are the names of the Blue, Indigo, Violet, Black, Brown); -- colors. No need for numerics\nThe following function evaluates many of the alternatives.\nfunction Evaluate (C : Color) return Integer is -- 1 Simple function declaration Result : Integer := 0; -- 2 Local variable\nbegin -- Evaluate -- 3 Comment the begin statement case C is -- 4 Start a case statement\nwhen Red => Result := 1; -- 5 The => is an association symbol when Blue =>Result := 2; -- 6 Am I blue? Set result to 2 when Black .. Brown => Result := 3; -- 7 For black through brown ... when Orange | Indigo => Result := 4; -- 8 For either orange or indigo when others => Result := 5; -- 9 others required for unspecified cases.\nend case; -- 10 Must use others if any cases are not specified return Result; -- 11 Compiler will look for a return statement\nTip: This is one of those powerful Ada syntactic constructs that can make code more readable and easier to maintain.\nIt is not always a good idea to initialize variables. You might get a valid result even if there is an error in the algorithm.",
        "transformed_text": "**Diary Entry: Exploring Ada Programming Constructs**\n\n**Date: October 15, 2023**\n\nDear Diary,\n\nToday, I delved deeper into the intricacies of Ada programming, focusing particularly on some fundamental constructs that make Ada stand out in the realm of software development. My exploration began with the simple yet crucial concept of comparison operators. In Ada, the equality operator is scoped to compare specific attributes, such as IDs in a list. This specificity ensures that comparisons are precise and relevant, avoiding any unintended side effects.\n\nMoving forward, I stumbled upon the short-circuit form of the if statement, which Ada elegantly supports through 'and then' and 'or else' constructs. These allow for conditional evaluations that are both efficient and clear, skipping unnecessary computations based on the outcome of the first operand. This feature not only enhances performance but also makes the code more readable and maintainable.\n\nMembership testing in Ada also proved to be straightforward and versatile, allowing checks across various data types and ranges. I implemented a function that tests whether a given data point falls within a specified range, which could be particularly useful in scenarios requiring validation or filtering of data.\n\nThe case statement in Ada was another highlight. Unlike the convoluted case constructs in C-based languages, Ada's case statements are straightforward and comprehensive, requiring that all possible cases be covered. This ensures that the code is robust and free from unexpected behaviors. I practiced with an enumerated type representing colors, where each color was associated with a specific integer value, demonstrating how Ada's case statements can elegantly handle multiple conditions.\n\nAs I reflect on today's learning, I am struck by how Ada's design prioritizes clarity, robustness, and maintainability. Each construct I explored today not only serves a practical purpose but also enhances the overall quality of the code. It's becoming increasingly clear why Ada is revered in critical systems where reliability is paramount.\n\nUntil tomorrow, when I plan to explore more advanced features of Ada,\n\n[Your Name]",
        "type": "narration",
        "tag": []
    },
    {
        "original_text": "bitsadmin rawreturn 4/13/2018 \u2022 1 min to read \u2022 Edit Online\nSyntax bitsadmin /RawReturn\nRemarks\nExamples\nC:\\>bitsadmin /RawReturn /GetState myDownloadJob\nAdditional referencesAdditional references\nReturns data suitable for parsing.\nStrips new line characters and formatting from the output.\nTypically, you use this command in conjunction with the Create and Get\\* commands to receive only the value. You must specify this command before other commands.\nThe following example retrieves the raw data for the state of the job named myDownloadJob.\nCommand-Line Syntax Key",
        "transformed_text": "In the digital realm where tasks are managed by Bitsadmin, a diligent and somewhat enigmatic program, there existed a command known as `/RawReturn`. This command was not like the others; it was precise, efficient, and had a singular purpose: to strip away the superfluous, leaving only the bare essence of information.\n\nImagine Bitsadmin as a wise old owl, perched high in the branches of the Command Tree, overseeing a bustling forest of data. Among the creatures of this forest were various jobs, each represented by different animals. There was myDownloadJob, a swift and tireless squirrel, always on the move, gathering acorns\u2014or in this case, data\u2014from far and wide.\n\nOne day, the owl received a request from a curious fox, who wanted to know the state of myDownloadJob. The fox was not interested in the usual verbose reports filled with new lines and formatting. It desired something raw, something that could be easily parsed and understood.\n\n\"Very well,\" hooted the owl, \"I shall use the `/RawReturn` command.\"\n\nWith a swift motion of its beak, the owl executed the command:\n\n```\nC:\\>bitsadmin /RawReturn /GetState myDownloadJob\n```\n\nThe forest fell silent for a moment as the command traveled through the digital winds, reaching the squirrel. The squirrel, ever diligent, responded with its current state, stripped of all unnecessary characters. The message was brief, direct, and exactly what the fox needed.\n\nThe owl relayed this raw data back to the fox, who nodded in satisfaction. \"Perfect,\" thought the fox, \"just the information I needed, without any of the fluff.\"\n\nThus, the command `/RawReturn` served its purpose, proving once again that in the world of Bitsadmin, efficiency and clarity were paramount. And so, the forest of data continued to thrive, with each creature knowing that when they needed the bare bones of information, the wise old owl and its `/RawReturn` command were there to help.",
        "type": "narration",
        "tag": []
    },
    {
        "original_text": "More C++ Idioms/Const auto ptr\nConst auto_ptr[edit | edit source]\nIntent[edit | edit source]\nTo prevent transfer of ownership of a held resource. Note: auto_ptr has been deprecated and is replaced by shared_ptr, unique_ptr and weak_ptr in C++11, thereby this idiom is no longer suggested.\nAlso Known As[edit | edit source]\nMotivation[edit | edit source]\nOften it is desirable to enforce a design decision of non-transferable ownership in code and enforce it with the help of compiler. Ownership in consideration here is of any resource such as memory, database connections and so on. const auto_ptr idiom can be used if we don't want ownership of the acquired resource to be transfered outside the scope or from one object to the another.\nauto_ptr without any cv-qualifier (fancy name for const and volatile) has move semantics as described in the Move Constructor idiom. It basically means that ownership of memory is unconditionally transferred from right hand side object to the left hand side object of an assignment, but it ensures that there is always a single owner of the resource. const auto_ptr can prevent the transfer.\nSolution and Sample Code[edit | edit source]\nDeclare the auto_ptr holding memory resource as const.\nconst auto_ptr <X> xptr (new X()); auto_ptr <X> yptr (xptr); // Not allowed, compilation error. xptr.release(); // Not allowed, compilation error. ( new X() ); // Not allowed, compilation error.\nCompiler issues a warning here because the copy-constructor of yptr is not really a copy-constructor but in fact it is a move constructor, which takes a non-const reference to an auto_ptr, as given in Move Constructor idiom. A non-const reference can't bind with a const variable and therefore, compiler flags an error.\nConsequences[edit | edit source]\n- An undesirable consequence of const auto_ptr idiom is that compiler can't provide a default copy-constructor to a class that has a const auto_ptr member in it. This is because the compiler generated copy-constructor always takes a const RHS as a parameter, which can't bind with a non-const move constructor of auto_ptr. The solution is to use Virtual Constructor idiom or use boost::scoped_ptr, which explicitly prohibits copying by denying access to assignment and copy-constructor.",
        "transformed_text": "In the realm of C++ programming, where concepts and objects often take on lives of their own, there existed a peculiar idiom known as the \"Const auto_ptr.\" This idiom was a clever trick, a safeguard against the whimsical transfer of ownership among the denizens of the codebase.\n\nImagine a world where every object, every piece of memory, and every connection to a database was an anthropomorphized character with a sense of belonging and a desire to remain in one place. The auto_ptr, a guardian of resources, was designed to ensure that these characters were never left ownerless, always passing from one caretaker to another with a firm grip.\n\nBut there were times when the auto_ptr's duty to transfer ownership was seen as a burden, a disruption to the natural order. Enter the const auto_ptr, a steadfast sentinel who vowed never to relinquish its hold. This const auto_ptr was a character of unyielding resolve, its constancy a symbol of its commitment to non-transferability.\n\nIn this narrative, the const auto_ptr is akin to a noble steed, loyal and unyielding, refusing to be ridden by another. It stands guard over its resource, a steadfast companion, never wavering in its duty. The compiler, a wise and ancient entity, recognizes the const auto_ptr's resolve and honors it, issuing warnings and errors to any who dare attempt to usurp its charge.\n\nThe consequences of this steadfastness are not without their challenges. Classes that harbor a const auto_ptr within their bosom find themselves without the blessing of a default copy-constructor, a rite of passage for many objects. Yet, in this world of anthropomorphized concepts, the const auto_ptr's dedication is respected, and solutions are sought through the Virtual Constructor idiom or the adoption of the boost::scoped_ptr, a cousin who shares the same disdain for the act of copying.\n\nThus, the const auto_ptr remains a symbol of constancy in a world where change is the only constant, a reminder that sometimes, the strongest bonds are those that cannot be broken.",
        "type": "narration",
        "tag": []
    },
    {
        "original_text": "logman 10/17/2017 \u2022 1 min to read \u2022 Edit Online\nSyntax logman [create | query | start | stop | delete| update | import | export | /?] [options]\nActions ACTION DESCRIPTION\nlogman create create a counter, trace, configuration data collector, or API.\nlogman query query data collector properties.\nlogman start | stop start or stop data collection.\nlogman delete delete an existing data collector.\nlogman update Update the properties of an existing data collector.\nlogman import | export import a data collector set from an XML file or export a data collector set to an XML file.\nApplies To: Windows Server (Semi-Annual Channel), Windows Server 2016, Windows Server 2012 R2, Windows Server 2012\nlogman creates and manages Event Trace Session and Performance logs and supports many functions of Performance Monitor from the command line.",
        "transformed_text": "**Diary Entry: Exploring Logman's Capabilities**\n\n**Date: October 17, 2017**\n\n**Time: 10:00 PM**\n\nDear Diary,\n\nTonight, I delved into the depths of Logman, a command-line tool in Windows Server that I've been meaning to explore for quite some time. As I sat at my desk, surrounded by the soft hum of my computer, I felt a surge of excitement. This tool, available in various iterations of Windows Server including the Semi-Annual Channel, Windows Server 2016, and even as far back as Windows Server 2012, promises to manage Event Trace Sessions and Performance logs, mirroring many functionalities of Performance Monitor directly from the command line.\n\nI started by creating a new data collector, a simple yet crucial task. The syntax was straightforward: `logman create`. This command allows the creation of counters, traces, configuration data collectors, or even APIs. It's fascinating how a few keystrokes can set the stage for extensive data collection and analysis.\n\nNext, I queried the properties of my newly created data collector using `logman query`. This action is akin to peeking behind the curtain, understanding the nuances of what I've just set into motion. It's essential for ensuring that everything is set up correctly before proceeding.\n\nFeeling confident, I initiated the data collection process with `logman start`. The simplicity of the command belies the complexity of what it triggers\u2014a series of events and data points being meticulously recorded. I paused, letting the system do its work, and then stopped the collection with `logman stop`. It's like pressing pause on a complex symphony, each note perfectly captured.\n\nI also explored the deletion and updating of data collectors. With `logman delete`, I removed a collector that was no longer needed, a clean-up process that ensures efficiency. Updating an existing collector with `logman update` was equally straightforward, allowing me to tweak settings without starting from scratch.\n\nLastly, I ventured into the realm of data collector sets, importing and exporting them via XML files using `logman import` and `logman export`. This feature is particularly useful for sharing configurations or backing up important setups.\n\nAs I wrapped up my session, I couldn't help but marvel at the power and versatility of Logman. It's a tool that, when wielded correctly, can provide deep insights into system performance and behavior. Tonight's exploration was just the beginning, but it has certainly whetted my appetite for more.\n\nUntil next time, Diary, keep these pages safe, just as Logman keeps data safe and accessible.\n\n**End of Entry**",
        "type": "narration",
        "tag": []
    },
    {
        "original_text": "6.1 Size of the executables ETFMS can run in two different modes: as various OS\nprocesses that communicate together (called an ETFMS net- work) or all the code in one process (called the mono process). Both modes have been compiled and run on Linux.\nHere, as an example, we compare the size of the mono -\nprocess using the Unix size command (text + data + bss).\n\u2022 Comparison of the size of the executables on HP-UX using the IP configuration as reference (Table 3).\nBuild Size Relative IP 89 MB 100%\nO2P 56 MB 63% OP 60 MB 67%\nTable 3: Size on HP-UX\n\u2022 Comparison of the size of the executables on Linux using the IP build as reference (Table 4).\nBuild Size Relative IP 65 MB 100%\nO2P 50 MB 77% OP 54 MB 83%\nTable 4: Size on Linux\n\u2022 Comparison of the size of the executables on HP-UX and Linux using the IP build on HP-UX as reference (Table 5).\nBuild HP-UX Linux IP 100% 73%\nO2P 63% 56% OP 67% 61%\nTable 5: Size comparison\nThe Linux executables are smaller than the HP-UX ex- ecutables. One factor explaining this difference is the zero-cost exception mechanism available on HP: exe- cutables contain pre-computed tables to improve the run-time performance when few exceptions are raised. The sizes should be remeasured with GNAT 5.01a which now supports zero-cost exception on Linux as well.\n6.2 Compilation performance To get an idea of the relative compilation speed, a num-\nber of significant files were compiled for different builds (IP, O2P, OP) on different platforms (HP-UX, Linux). Note that GNAT 5.01a was used for this section.\nTable 6 gives the compilation times (user + system cpu) for different builds.\nIn Table 7, each IP build is used as reference to give rel- ative times for each machine.\nOn both HP and Linux, the compilation time for an O2P build is roughly 50% more than for the IP build. Due to the back-end inlining, the OP build requires significantly more time: about 3 times as much as the IP build and 2 times as much as the O2P build.\nBuild HP Workstation HP Server Linux-PC IP 3m50s 2m16s 0m46s\nO2P 5m53s 3m01s 1m18s OP 12m47s 6m26s 2m48s\nTable 6: Compilation times\nBuild HP Workstation HP Server Linux-PC IP 100% 100% 100%\nO2P 153% 133% 170% OP 333% 284% 365%\nTable 7: Relative compilation time per machine\nThe IP compilation on HP Workstation is used as refer- ence in Table 8.\nBuild HP Workstation HP Server Linux-PC IP 100% 59% 20%\nO2P 153% 79% 34% OP 333% 168% 73%\nTable 8: Relative compilation time\nThe tables 6 and 8 show that compiling on a regular PC is significantly faster than on HP workstations and even on HP servers.\nThe last table (Table 9) is adapted to take into account the machine\u2019s CPU speed, i.e. the figures have been adjusted by CPU clock frequency to indicate what might be expected at equal processor MHz.\nBuild HP Workstation HP Server Linux-PC IP 100% 129% 100%\nO2P 153% 173% 170% OP 333% 367% 365%\nTable 9: Relative compilation time per MHz\nFor compilations, we see that 1 Intel MHz on a Linux PC is roughly equivalent to 1 PA RISC MHz on an HP-UX ma- chine. In other words, the difference in the instruction set and operating system has no significant impact on the com- pilation speed. The main factor influencing the compilation speed is the raw processor speed (of course if the machines have enough memory to avoid paging).\nAs GNAT supports parallel compilations, it is thus inter- esting to see if a multi-CPU server can be used to compile a big application faster. Experiments done on a 4 CPU HP server have shown that parallel compilation scales very well. From our experience, a good guideline is to launch N+1 par- allel compilations on a N CPU system; this is valid even for a single CPU system.\n6.3 Execution performance A heavy test reprocessing a significant set of ETFMS in-\nput flight and radar data was used to get an idea of the rela- tive execution speed. This was done with the mono process\nand hence does not depend on the number of processors",
        "transformed_text": "In the realm of digital computation, where binaries dance and processors hum, there existed a peculiar ensemble of executables known as ETFMS. These were not ordinary programs; they had the unique ability to operate in two distinct modes: as a network of intercommunicating processes or as a solitary, all-encompassing monolith. This narrative explores their journey across different operating systems, particularly their encounters with Linux and HP-UX.\n\nETFMS, in their anthropomorphized form, were akin to a troupe of actors, each with a role to play. When they chose to perform as a network, they were like a band of musicians, each playing a different instrument but together creating a harmonious symphony. In their monolithic form, they were a solo performer, every note and rhythm emanating from a single source, yet no less captivating.\n\nTheir sizes were a topic of much discussion among the digital denizens. On HP-UX, the lead actor, IP, stood tall at 89 MB, a veritable giant. His companions, O2P and OP, were more modest, measuring at 56 MB and 60 MB respectively. However, when the troupe migrated to Linux, they seemed to shed some of their bulk. IP now scaled down to 65 MB, while O2P and OP adjusted to 50 MB and 54 MB, respectively. This\u7626\u8eab was attributed to the absence of certain performance-enhancing tables that HP-UX executables carried, like a backpack filled with tools for rare emergencies.\n\nThe compilation of these digital dramas was another spectacle. Using the latest version of GNAT, the compilers worked tirelessly. On HP-UX, the compilation times varied significantly depending on the build and the machine's capabilities. The IP build, a standard by which others were measured, took 3 minutes and 50 seconds on an HP Workstation, while the O2P and OP builds stretched to 5 minutes and 53 seconds and 12 minutes and 47 seconds, respectively. The Linux-PC, however, proved to be a swift stage, where the IP build finished in just 46 seconds, with O2P and OP following in 1 minute and 18 seconds and 2 minutes and 48 seconds.\n\nExecution performance was the final act in this digital play. A rigorous test, reprocessing a vast array of ETFMS input data, was conducted. The mono process, independent of processor count, showcased the true mettle of these executables. Despite the differences in their sizes and compilation times, their performance on stage was a testament to their versatility and robustness.\n\nThus, the tale of ETFMS is one of adaptation and performance, a story of how digital entities navigate through different environments, always ready to transform and excel, no matter the platform or the mode.",
        "type": "narration",
        "tag": []
    },
    {
        "original_text": "Logic for Computer Science\n| A Wikibookian suggests that Logic for Computer Scientists be merged into this book.\n|\nDiscuss whether or not this merger should happen on the discussion page.\nThis book discusses logic as a tool for computer science; a field that uses logic at all levels. It provides a survey of mathematical logic and its various applications. Some areas where it is particularly important include:\n- Digital circuit design\n- Complexity theory (NP equivalent to Existential second-order logic)\n- Database Systems (SQL; roughly predicate/first-order logic)\n- Computer-aided verification (Temporal logic & model checking)\n- Programming languages (lambda calculus)\n- AI, expert systems, inference engines\n- Distributed Systems\n- Logic Programming\n- Computer Security\nAfter covering basic material of propositional logic and first-order logic, the course presents the foundations of finite model theory and descriptive complexity. Other topics, including logic programming, non-monotonic reasoning, temporal logic, and reasoning about knowledge and belief, are surveyed as time allows. These notes were taken by student scribes.\nTable of Contents[edit | edit source]\n|\n|\nReferences[edit | edit source]\nYou may also find the following references useful\n- Mathematical Logic. H.-D. Ebbinghaus, J. Flum, and W. Thomas\n- Foundations of Databases. Abiteboul, Hull, Vianu. Available here: \n- Computational Complexity. Christos H. Papadimitrou.\n- Elements of Finite Model Theory. Leonid Libkin.\n- Finite Model Theory and Its Applications. Gr\u00e4del, Kolaitis, Libkin, Marx, Spencer, Vardi, Venema, Weinstein\n- G\u00f6dels Proof. Ernest Nagel and James R. Newman\n- Language, Proof, and Logic. John Barwise and John Echtermendy\n- A Profile of Mathematical Logic. Howard DeLong",
        "transformed_text": "In the bustling realm of Computaria, where logic reigned supreme, a group of anthropomorphized concepts gathered to discuss the intricacies of their world. At the heart of Computaria was the Grand Library of Algorithms, where the books on Logic for Computer Scientists and Logic for Computer Science lay side by side, their spines gleaming under the soft glow of binary lights.\n\nThe propositional logic, a wise old owl, often perched atop the highest shelf, his eyes twinkling with the knowledge of truth tables and logical connectives. Below him, the first-order logic, a diligent beaver, meticulously chewed through quantifiers and predicates, ensuring every statement was rigorously checked.\n\nOne day, the propositional logic and the first-order logic convened with the digital circuit design, a clever fox, who wove intricate patterns of AND and OR gates, and the complexity theory, a thoughtful tortoise, who pondered the depths of NP problems and existential second-order logic.\n\nThe database systems, a gregarious pack of wolves, howled about the forests of SQL, their howls echoing the structure of predicate logic. Meanwhile, the computer-aided verification, a vigilant hawk, soared high, her keen eyes scanning for flaws in temporal logic and model checking.\n\nIn the lush valleys of Programming Languages, the lambda calculus, a serene deer, grazed peacefully, her antlers branching into recursive functions and abstraction. The AI, expert systems, and inference engines, a trio of playful otters, darted through the streams of machine learning and decision-making algorithms.\n\nThe distributed systems, a colony of industrious ants, worked tirelessly to maintain the harmony of their interconnected network, while the logic programming, a meticulous spider, spun webs of declarative statements and Horn clauses.\n\nIn the shadowy corners of Computaria, the computer security, a watchful owl, guarded the borders, her eyes alert for any breaches in encryption and authentication.\n\nAs the seasons changed in Computaria, the concepts gathered in the Grand Library, their discussions ranging from finite model theory to descriptive complexity, from logic programming to non-monotonic reasoning, temporal logic, and reasoning about knowledge and belief.\n\nThe notes taken by student scribes, young mice scurrying to capture every word, were stored in the vast archives of Computaria, alongside timeless references like Mathematical Logic by Ebbinghaus, Flum, and Thomas, and Foundations of Databases by Abiteboul, Hull, and Vianu.\n\nThus, in the land of Computaria, logic was not just a tool but a way of life, woven into the very fabric of existence, guiding the anthropomorphized concepts through the intricate dance of computer science.",
        "type": "narration",
        "tag": []
    },
    {
        "original_text": "How Wikipedia Works/Chapter 4\n- Understanding and Evaluating an Article\nOnce you've found the content you're looking for, the next thing you need to know is what you're looking at. With an understanding of namespaces and content types in Wikipedia, you can easily tell whether you're looking at an article, a discussion page, a community page, or a user page; and once you know how to search and browse the site, finding articles on your topic is simple. The next step is assessing an article's quality.\nUnderstanding how to read all the components of an article\u2014from its edit history to its discussion pages\u2014is key for skilled and sensible reading of Wikipedia. Experienced editors and readers use many tricks to quickly evaluate pages and understand their state. It's a matter of knowing where to look and determining which clues are most significant.\nIn this chapter, we'll identify the different parts of a typical article and discuss what each part can tell you. We'll then list some detailed questions to ask when critically evaluating an article. Throughout this chapter, as we describe how articles are put together, we'll list Clues\u2014points to pick up on for quality evaluation. If you're in a hurry, we've summarized our best clues at the end of the chapter. Note\nIn this discussion of the look and feel of Wikipedia, we'll be talking about viewing pages with the default configuration, the Monobook skin. Skins are customizable, and there are a variety to choose from; for more, see \"Setting Your Preferences\" on Section 1.1.6, \u201cCreating the Account\u201d.\nAnatomy of an Article[edit | edit source]\nEvery editable page on Wikipedia is made up of three related parts: the text of the page or article, the page history, and a separate discussion page. The tabs that are visible at the top of (almost) any page are your entry points to these components. There are four tabs if you are logged out and six if you are logged in.\nAssuming you're logged in, the tabs you'll see are shown in Figure 4.1, \u201cThe tabs at the top of a Wikipedia page\u201d: Article, Discussion, Edit This Page, History, Move, and Watch.\n- The Article tab shows you the text of the article you are viewing; this is the default view when you go to a page and the view you'll want to return to after exploring other components. The title of this tab changes across namespaces; for instance, it displays as Project Page if you're looking at a page in the Wikipedia namespace, and User Page if you're looking at a page in the User namespace.\n- The Discussion tab shows you the discussion or talk page for that article; this is a separate page dedicated to discussion of the page's content.\nFigure 4.1. The tabs at the top of a Wikipedia page\n- Note: The terms talk page and discussion page are used somewhat interchangeably. Although the tab intended for discussion of an article is labeled Discussion, it leads to a page located in the Talk namespace. Discussion pages attached to user pages, which are intended for conversation between editors, are called talk pages as well\u2014though, to be pedantic, they are user talk pages in the User talk namespace.\n- The Edit This Page tab allows you to edit whatever page you are currently viewing. Clicking the tab opens up an edit window, where you can modify the text of the page.\n- The History tab shows you the edit history of the page you are viewing.\n- The Move tab moves the page to a new title. Leave this advanced operation alone for now, until you've had a chance to read Chapter 8, Make and Mend Wikipedia's Web.\n- The Watch tab adds the article you're currently viewing to your own personal watchlist. (If you are already watching an article, the tab will display Unwatch instead and clicking it will remove an article from your watchlist.)\nIn this chapter, we'll cover articles as a whole along with talk pages and history pages. Editing is discussed in Part II, from Chapter 5, Basic Editing onward, and then we'll return to watchlists in Chapter 11, Becoming a Wikipedian.\n- Absent Tabs: There are some exceptions that apply to the tabs you can view on a particular page. Protected pages, for instance, won't display an Edit tab, but will instead display a View Source tab that shows the wikisource of an article but doesn't allow you to edit it. Pages in the Special namespace, which are not editable, don't display any of these tabs. If you aren't logged in, the Move and Watch tabs are not available.\nThe Article Text[edit | edit source]\nDid you ever wonder what makes Wikipedia articles seem so standardized? The conventional way of writing a Wikipedia article combines a number of recognizable features, which will generally appear as an article matures. In this section, we'll review the different parts that you may encounter in an article. Clue: All articles don't have to have all of these parts, but if you see an article without any of them\u2014or if the text appears unformatted\u2014chances are good the article was added by an inexperienced editor.\nDirectly underneath the page tabs, you'll see the title of the page you're viewing in large bold type, followed by a line and the words From Wikipedia, the free encyclopedia. This is where the editable portion of the page starts.\nLike trailers before a feature film, messages may appear in italics at the beginning of an article. These messages are not part of the article, but are a rubric properly called a hatnote. Hatnotes point you toward disambiguation pages or other articles that might be confused with the one you are viewing; for example, For the medical term see rigor (medicine) occurs at the top of rigour. You may also see one or more warning messages in brightly colored boxes at the beginning of articles; for instance, warning you that this article requires attention from an expert or the neutrality of this article is disputed. Other messages may simply note that some kind of cleanup needs to happen on the article. These messages serve two purposes: They alert the reader to problems, and they let editors know that \"something needs to be done here.\" They are produced with templates (see a list at Wikipedia:Template messages), and any editor may add (or remove) any template, so they are not particularly \"official.\" They are, however, useful alerts to many kinds of quality issues, and they tell you that at least one editor has concerns about the article.\n- Color Coding\nArticle warning messages are of a standard shape (slim and rectangular) and are color coded: orange for content issues, red for a deletion candidate, and yellow for cleanup. Blue is used for any general informative messages. See Wikipedia:Article message boxes, shortcut WP:AMB, for a full explanation.\nFollowing any messages, the text of the article itself begins. Often the article text is broken up into numerous sections, which should convey a logical structure to the article and break it into manageable pieces. If there are three or more such sections, a Table of Contents (ToC) is automatically displayed. Clicking any of the links in the ToC takes you directly to that section of the article. You can hide a lengthy ToC by clicking the [show/hide] link; if you are logged in, you can also disable all ToCs from showing in your user preferences.\nRegardless of how many sections there are, the article should start with a strong introductory paragraph that tells you the topic of the article and why it is important.\nThe text itself should also be sprinkled throughout with internal links, or wikilinks, to other articles; these links are displayed in blue. Clue: If no wikilinks exist in the text, there's a strong chance the article was written by someone unfamiliar with Wikipedia's conventions, and the article itself may be questionable.\nThe text may also contain images (which should have captions) or graphics that summarize information about the topic. To see the full-size image and more information about it, simply click the image; this takes you to the image description page.\nYou may also see an infobox near the beginning of an article, typically on the right-hand side. These boxes are standardized presentations of key facts about the article's topic. Different styles of infoboxes have been developed for articles in many diverse fields, from species of plants to Australian cricketers. They are all based on templates, which are described in Chapter 9, Images, Templates, and Special Characters. Clue: Authors do not sign anywhere in articles, so if you see a signature in article text, it was left by someone unfamiliar with Wikipedia's conventions.\nFor references, the article may contain footnotes or inline references. Sometimes external links are embedded in the text; this referencing style is discouraged, however, in favor of footnotes. Footnotes will appear as small superscript numbers at the ends of sentences; clicking the footnote number takes you to the appropriate footnote at the end of the article and vice versa; clicking the caret (^) at the beginning of a footnote takes you back to the text.\nAt the end of a good article, you'll find several standardized sections: See also, References, and External links. (On a disambiguation page, which serves as a dedicated navigational structure to point you to articles with related names, these aren't used.) The See also section should include a list of other relevant Wikipedia articles. Generally, articles that are already linked in the text are not included in this section. References, sometimes called sources or notes, include the sources used in writing the article. When present, footnotes are often listed here, or in a Notes section appended to the references. The External links section includes links to other relevant non-Wikimedia websites on the topic. For instance, if the article is about a company or organization that has a homepage on the Web, a link to this site should be included in External links.\nThere are occasionally Bibliography and Further reading sections included as well; the former may list publications by the subject of the article, whereas Further reading may list other important sources of information that aren't directly cited in the article. There may also be links to other Wikimedia sister projects in this section\u2014for example, links to related media on the Wikimedia Commons or to a dictionary definition of a term on Wiktionary. There may also be messages in this section explaining that material has been imported from a non-copyrighted source. Clue: Any material imported from another source, such as an old encyclopedia, may need to be updated.\n- Reference and Research\nThe more critical attention you are giving an article and the more seriously you are researching a topic, the more the article's references are going to interest you. Though this is far from always being the case, references should be a mixture of online and paper sources and of recent works along with standard texts that give broad context. A good References, External links, or Further reading section can be a great place to start doing research, especially if you are new to a topic.\nAt the very bottom of the article, you find any stub messages. A stub, as mentioned in Chapter 1, What's in Wikipedia?, is simply a short or beginning article that may be incomplete. Stub articles are sorted by topic and identified with these short template-based messages that tell you the article is a stub and what broad topic category it falls into. Clue: A stub article will likely be incomplete in terms of the information provided\u2014seeing a stub message is an alert to check other sources as well.\nA small box listing the categories into which the article has been placed follows the body of the article. Clicking any of these category links takes you to the category page, which lists other related articles in the same category. Clue: All articles should be in at least one category. An article that doesn't have any categories listed is likely new or orphaned.\nBacklinks[edit | edit source]\nIf you want to place an article in a broader context, or if you're researching a topic in depth, the What Links Here link in the sidebar can be useful. Clicking this link shows you other pages that link to the article you are currently viewing. In other words, this link gives you a list of backlinks\u2014places where your article is referenced on other pages. Checking the backlinks is one of the tricks of the trade for getting the most out of Wikipedia.\nFor an article on a basic topic, there may be a great number of other articles that link to it, and there may be too many backlinks to tell you anything useful. You won't learn a great deal from the backlinks to the article on New York, except that they are very numerous indeed. On the other hand, only a handful of articles may link to a more obscure article. For instance, for a historical figure you are researching, the backlinks may well turn up points of entry to research further: articles about events that occurred during their lifetime or lists of officeholders that include the person of interest. Don't assume the article itself will send you to all those other pages in its See also section\u2014articles are always works in progress. Searching the site for the article's title won't necessarily turn up all the references to it on other pages, either, if the references are hidden in internal wikilinks with different alternate text. Using What Links Here will catch all the references to an article, however, including where it may have been discussed on user or project talk pages. If you're checking the quality of an article, it's always worth checking the backlinks.\nNo backlinks at all means you have found an orphan, which is considered a debilitating condition. An orphaned article is unfortunate and possibly suspect, alerting the reader to issues of potential concern. It may simply be that the article is new and no other articles have had a chance to link to it yet, or it could be a topic that is not really encyclopedic. If an article claims to be about an important topic, but nothing links to it, it may well be a hoax. Check to see how old the article is, as described in the next section. Clue: No incoming links can also mean the article has a poor choice of title, perhaps not conforming to Wikipedia style. It is also conceivable that an orphaned article has a typo in the title (for instance, a subtle error such as the wrong punctuation or Mc instead of Mac). If this is the case, it's worth searching for other articles about the same topic, as described in Chapter 3, Finding Wikipedia's Content.\nArticle History[edit | edit source]\nOnce you've read an article thoroughly, you want to understand its next important aspect\u2014how to read its history. Every page on Wikipedia, whether an article, a talk page, or any other page (except for the auto-generated special pages), has a record of all changes made to it that is captured in the page history.\nPage histories are revealing to those in the know. The goal of reading a page history is often to determine the story of what has happened to an article over time. How old is an article? How many and which editors have worked on it? Has the topic been contentious, the subject of debate between editors? Has the page improved over time, or has any good content been lost? Was a particular edit valuable to the article? Is the current version that you're looking at vandalized? The page history can answer all of these questions and can also give you a good idea of an article's trustworthiness. Experienced Wikipedians glean a great deal about articles from looking over the page history and then following up on some of the individual edits that make up that history. Clue: How contentious the article topic is matters, because a subject that turns into a combat zone often drives off all but highly partisan editors; with careful investigation, the page history can tell you whether this is the case.\nThe page history is accessible by clicking the History tab at the top of the page. The History tab always leads to the history of whatever page you're looking at. For instance, if you are viewing the talk page of an article, clicking the History tab will take you to the history of edits to that talk page, rather than the history of the article it's associated with. Go back to viewing the article, and then click the History tab to see the article's history.\nSubstantial articles usually have a number of contributors. If the page history indicates that the page is entirely or almost entirely the work of one person, you are dealing with a situation more comparable to evaluating an article on someone's private website. Clue: A short history is a warning sign. If only a few people have edited an article, it is likely that only a few people have reviewed the factual content, and the page may represent a limited view of the topic.\nYou Can't Change Wikipedia\nYou can't actually change anything in Wikipedia \u2026 you can only add to it. An article you read today is simply the current draft; every time it is changed, both the new version and a copy of the old version are kept. This allows you to compare different versions and restore older content if necessary. Except for page deletions (discussed in Chapter 7, Cleanup, Projects, and Processes), no content is ever actually removed from Wikipedia. (Adapted from Wikipedia:Ten things you may not know about Wikipedia)\nEven in a long history, however, some edits should be discounted as being of little significance to the content. A number of editors may have simply made minor formatting changes to an article. Some passing bot may have edited it mindlessly. These contributors may not have verified any of the content but have simply brought the article up to Wikipedia stylistic standards. A common situation is that a single contributor has written the bulk of a short or beginning article, and then a few people will reformat the article but not change the content substantially. In these cases, there is still only one primary author.\nReading a Page History[edit | edit source]\nFirst and foremost, the page history tells you who has worked on the page, and it allows you to examine the successive versions of the article and the differences between them (see Figure 4.2, \u201cReading a page history, accessible from the History tab\u201d). You can also see the date and time of each edit and compare versions of edits. Finally, you can see the comments that contributors have left in the Edit summary field regarding their edits.\nEach line in the page history represents a single edit. Every time a wiki page is modified and saved, a new version of that page is saved, and a new line is added to the page history. The most recent version is displayed at the top of the history, so reading down is reading back into any page's history.\nEvery line in a page history has several elements. Reading across, they are as follows:\n- First are two links, curr and last, along with a radio button. Clicking curr for a particular version compares it to the most recent version of the article (so you can see how that version compares to the version currently displayed on the site), whereas clicking last compares a particular version to the immediately preceding version (so you can see exactly what was changed with that particular edit). The radio buttons allow you to compare any two versions of an article, as described in \"Analyzing a Page History\" on Section 1.3.2, \u201cAnalyzing a Page History\u201d.\n- Next, the date and time of the edit are displayed as a blue link. By default, this time is set to display in the UTC time zone. (You can change the time to your local time zone if you are logged in by going to My Preferences, as described in \"Setting Your Preferences\" on Section 1.1.6, \u201cCreating the Account\u201d.) Clicking this link will show you that particular version of the page. When you're viewing an old version, a warning message is displayed at the top of the page, and the page URL in your browser will display the version number, or unique ID, of the version you are looking at. You can use this URL to link to this particular revision of the page. (This is also how Permanent Link on the left-hand sidebar works.)\n- Next, the author of the edit is displayed. This author will be listed by either a username (if the editor was logged in) or an IP (Internet Protocol) address (if they were editing anonymously). Clicking the username will bring you to the editor's user page, if he or she has one; if the username is displayed as a redlink, that means the editor was logged in but has not yet created a user page. If an editor was not logged in, the numeric IP address of the computer he or she was editing from will display instead, and clicking the IP address will bring you to a list of that IP's contributions.\n- After the editor's name, there are links in parentheses to the editor's user talk page (Talk) and, if the editor is logged in, his or her contributions (contribs). Whether an editor was logged in or not, you can go to his or her talk page to leave a message. Clue: If you suspect vandalism, it can be particularly helpful to go the talk page to see if a particular editor has racked up any warnings from other editors. Again, a redlink means there are no messages yet on an editor's talk page. Clicking the Contribs link shows you a list of all the edits that particular editor has ever made.\n- Next, some edits will display a lowercase m if the edit was marked as minor by the editor; minor edits are generally small changes, such as spelling or typo corrections. The number in parentheses that follows (for edits made since mid-2007) shows the number of bytes that were changed with that individual edit; a large number is generally reflective of the entire article being edited and saved. (Somewhat more usefully, the net number of bytes changed with a single edit is also displayed in Recent Changes and in personal watchlists).\n- Finally, any text that follows is part of the edit summary provided by the editor. This is (one hopes) an informative comment that is intended to describe what the edit accomplished and why it was made. Sometimes these summaries are created automatically and contain a variety of links; often they contain a kind of shorthand or jargon that has been developed over the years.\nProblem IPs\nIf an edit was made by a user who was not logged in, you can at least get a look at the other contributions made using the same IP address. But remember that the same IP address may represent different people editing, and different IPs may represent the same person, because Internet service providers don't always operate IP allocations in the simple way that telephone numbers are handed out. Many Internet service providers issue temporary IP addresses to their users from a pool of addresses, and when the user disconnects, the address is returned to the pool for allocation to someone else. These are known as dynamic IPs. (IP numbers that differ only in the last three places may be the same editor using a dynamic IP.) Furthermore, even if an IP address is fixed, it might be the IP for a computer in a public place, such as a library, an Internet caf\u00e9, or a school. This means, of course, that you may be seeing many people's contributions from the same IP address, and you cannot be sure a message left on the talk page will reach a particular user. IP addresses from public settings can sometimes reveal an extreme and baffling combination of excellent edits and vandalism. However, you still might be able to see that the particular edit occurred in the midst of a series of edits, which can help you gauge the character of whoever was at that machine at that time. If they've been determined to be from public computers, the discussion pages for IP addresses will sometimes have notices to this effect.\nAnalyzing a Page History[edit | edit source]\nComparing versions of an article, or examining diffs, is the most useful tool an editor has for determining how an article has changed over time. Diff is short for the differences between pages. The term diff is also commonly used as shorthand to refer to a particular old version of a page.\nChecking the diffs can tell you not only how the page has changed over time but also if the current version displayed is the best one. If you suspect vandalism in the current version, for instance, flip back a change or two, using the radio buttons or the curr and last links, to see if the information persists. If something in the article seems untrue, it's worth comparing versions until you can determine when it was added and by whom. (After all, if you can ask the person who edited something into the article about the edit, you can perhaps get somewhere with your difficulty.)\nBecause all versions of a page are kept, any two versions can be compared. To do so, choose the radio button for the version you are interested in looking at. Another radio button will appear for all versions of the page that are newer than the one you chose. Choose this new right-hand radio button for the newer version you are interested in. (To compare to the most current version, choose the top radio button.) Now click the Compare Selected Versions button at the top of the page history.\nA split screen will appear with two headers, as shown in Figure 4.3, \u201cA diff is accessible by clicking Compare Versions on the page history. The newest version is shown on the right. Shading indicates a changed paragraph. The editor's name, the date and time of the edit, and the edit summary are listed at the top.\u201d, each of which tells you the version date and time, the edit author, and his or her edit summary. The version on the right is always the newer version of the two you have selected. You will then see a line-by-line comparison of the wikisource of the two versions you have selected. On the old version, paragraphs that differ from the new version are highlighted yellow, and on the new version, they are highlighted green. Text removed within a paragraph is shown in red on the old version, whereas new text within a paragraph is shown in red on the new version; if a whole paragraph was removed or added, the text is simply black, whereas the other side is blank (white).\n- Undoing Vandalism\nAny old version of a page can be edited and resaved to become the most current version, overriding any other edits. When this is done to undo a single edit, it's called reverting that edit. Reverting is how mistakes can be easily fixed, as explained in Chapter 5, Basic Editing, and how most vandalism is removed, as explained in Chapter 7, Cleanup, Projects, and Processes.\nBelow this highlighted summary of changes, the entire rendered view of the more recent of the two versions you are comparing is displayed. Note that you can change this view in your user preferences, under Misc.\nIf no line-by-line differences are displayed, there are no differences between the two versions of the page. If there are also intermediate edits in between the two versions you are comparing, the comparison will tell you this (for example, 5 intermediate edits not shown). Only differences that occur between the two versions you are comparing are displayed.\nIf an edit was made by a registered user, you can follow up by going to that user's page to see who he is (or at least who he claims to be). Associated with each user page is the accompanying user talk page, which can give you a flavor of the user's interactions with other users: Is it full of thank-you notes or vitriolic arguments? Clicking the contributions of any particular contributor shows you the edits this particular person has made in Wikipedia. Clue: Is this a new or experienced contributor? What else has he or she been working on?\nYou'll sometimes need to find the exact revision in the history when a particular piece of information was added to an article. Perhaps you need to know who added a questionable statement or what the reasoning was behind adding a cleanup tag to the article. You could simply go back from the current revision one diff at a time, comparing each version until you find the one you are looking for. This method works well for articles with very short histories, but quickly becomes tedious for an article with a long edit history. Rather than doing this, then, there are a few tricks for quickly reviewing long page histories:\n- First, at the top of the page history, set the number of changes viewable to 500 rather than 50, so you can see all of the history (or at least more of it) on a single screen.\n- Quickly scan the edit summaries\u2014does anything pop out? If, for instance, you are looking for the addition of a cleanup tag, does anyone mention adding this tag? Using CTRL-F to do a search for a particular term can sometimes be helpful.\n- If you don't find the version you're looking for, skip back a large number of changes and bisect the edit history by picking a revision somewhere in the middle. Review this revision by clicking the linked date or compare it to the current revision using the radio buttons. Is the information you're looking for in this old revision?\n- If so, keep going back several changes at a time until you find a version where it's not present. If not, go forward several changes until you find a version where it is present.\n- Once you've done this, you'll have located two revisions on either side of when the information you're looking for was added\u2014one before the information was added and one after (the earliest revision you found that included the information). Once you've narrowed down a range in this manner, work your way backward and forward within the range a few revisions at a time, comparing revisions using the radio buttons.\n- Narrowing down the exact diff when something was added is usually quick. You can then follow up by checking the editor's edit summary and other contributions and determining whether it seems like a trustworthy edit.\nEdit Summaries and Minor Edits[edit | edit source]\nWhen reading page histories, you'll see comments and explanations. These are edit summaries, short comments provided by editors to help explain their edits. Edit summaries display in the page history, Recent Changes, and in user watchlists. The ideal edit summary briefly explains the nature of the edit and gives some context for it (for instance, not simply saying rewriting but rewrote 2nd paragraph for grammar and clarity). Edit summaries don't have to be complicated. If you make a test edit yourself, add test in the Edit summary box. When you reverse the edit, simply write undo test in the box.\nEdit summaries are optional (though a very good idea), and even if present, they may be cryptic because a large body of jargon has been developed over the years. For instance, you might not be able to fathom avoid dab the first time you see it, but it is shorthand for avoided a disambiguation page, which, in turn, means that a link was fixed to point to an appropriate article instead of to a disambiguation page. To wikify a page is to add appropriate wikilinks to a page, by linking appropriate words, names, and phrases to other articles; it is one of the most common operations, as editors weave the web of the wiki, and it may also appear in a summary as wfy.\nThere are also some edit summaries that are automatically added by the software. For instance, the title of the section that was edited is automatically added and appears in grayed-out type in edit histories. Occasionally, you will see small conversations between editors as they go back and forth on a point (edit summaries are not indexed or searchable, however, so any really important discussion should always go on the talk page). Edit summaries can contain wikilinks if needed.\nRefer to Appendix C, Edit Summaries Jargon or Appendix D, Glossary or Wikipedia:Edit summary legend (shortcut WP:ESL) for other possible terms that may occur in edit summaries. If you are having trouble figuring out an edit summary, compare the version in question with the immediately preceding version. The diff should make things clear.\nIn assessing an article, look for edit summaries that indicate reversions of a page to a previous state. These will be denoted by revert or abbreviations such as rv or rvt, and indicate either reversal of vandalism or editors disagreeing on a point. Clue: A patch of edits with many reverts in a page history indicates some sort of editing war. The quality of articles, unfortunately, is likely to degrade sharply in an extended edit war, so be warned.\nAnother important warning sign is an editor who never bothers with edit summaries. Clue: Especially if the editor is editing as anonymous, rather than editing with an account, you should treat such uncommented edits with suspicion.\nThe lowercase bolded m that sometimes appears next to the edit summary refers to a minor edit. This edit is one that the editor deemed small enough that it doesn't have to be reviewed by other editors. Examples of minor edits include spelling and grammar corrections, link fixes, and small formatting changes. Edit summaries for minor edits, if they exist, are often quite short: typo or spp for a spelling correction. Only logged-in users can mark an edit minor. While logged in, you can also choose to exclude minor edits in your views of the Recent Changes page and your watchlist.\nFurther Reading[edit | edit source]\n About backlinks\n How to read a page history\n An introduction to the edit summary and more information about automatic edit summaries\n A glossary of commonly used edit summaries; helpful if you come across an abbreviation you don't recognize\n How to read the difference between two versions of a page\nTalk Pages[edit | edit source]\nDiscussion or talk pages are meant for discussion about articles and other pages. Nearly every page on Wikipedia has an attached, dedicated discussion page. These pages exist in the various Talk namespaces. You access or create a talk page by clicking the Discussion tab; if the type is blue, the page already exists; if it is red, you will be creating it.\nTalk pages are important, socially and practically. They help strengthen content, and they're also an integral part of Wikipedia's community. Talk pages are the \"grass roots\"\u2014they function as a space for conversation between all the readers and editors of an article. Editors can mention possible problems, leave notes about current or ongoing work on the article, and negotiate a way through conflicts on content. Wikipedia's main aim, to build up its editing community and improve the articles that have been started, is played out here. Talk pages play a large part in making Wikipedia work by keeping discussion close to the article's content, rather than on a centralized discussion forum. And anyone may take part, even if they're not logged in.\nWe mention how talk pages work early on in this book, not because you're necessarily going to post to them immediately, but because talk pages are essential components of articles, and they often carry important information about an article's quality. Examining talk pages is key to evaluating articles properly.\nReading and Contributing to Talk Pages[edit | edit source]\nTalk pages provide a way for people to discuss articles without leaving comments in the actual article itself. They also provide a handy place for WikiProjects and other editing projects (discussed further in Chapter 7, Cleanup, Projects, and Processes) to place evaluations and messages. The beginning of a talk page may have several templated messages, warnings, or ratings, as well as links to archives of older talk page discussions.\nSooner or later, as a reader of Wikipedia you will disagree strongly enough with something in an article to want to do something about it. Or perhaps some point in an article is a mystery, and you'd like a reference to another source. Although you can simply edit the article, the best way to express concerns or get feedback or help from others working on the article is to leave a message on the talk page. If necessary, start a new thread yourself. Simply edit the page by clicking the Discussion tab to go to the talk page, and then the Edit This Page tab or the New Section tab. Add a new section or a new comment, as described here.\nA given conversation may be joined by two, three, or dozens of contributors. Talk page discussions usually consist of threaded comments below a topical header; the most recent comment is at the bottom. Replies to a comment are placed underneath it and are indented to help the dialog stand out more clearly. At least that is the theory: Complex discussion often generates branches within one thread or page section. Editors may want to come back to some point made higher up the page; if so, they should use deep indenting to try to keep the side-issue clearly delineated. Unlike contributions to articles, comments are signed by their authors.\nBy convention, each new topic on a discussion page is set off from the previous topics with a header like this:\n==sheep foraging habits== I was just wondering: what is the deal with the foraging habits of sheep? do the listed references cover this? I think we need some more detail about this important topic. -- Phoebe 19:11, 13 Jan 2007 (EST)\nUsing the ==Heading== formatting will add a heading to your comment, which will create a table of contents automatically. Add a new comment, with a header, to the very bottom of the page, below any other text that appears in the source box; then click Save at the bottom of the page. Alternatively, use the New Section tab, which allows you to start a new section without needing to edit the whole page. The Subject/Heading field will become the section heading for your comment. When you use the Post a Comment feature, shown in Figure 4.4, \u201cPost a Comment tab from a talk page\u201d, the section heading will also become the edit summary, so you don't need to create a separate edit summary when you save the page.\nFigure 4.4. Post a Comment tab from a talk page Post a Comment tab from a talk page\nYou can indent comments with a bullet point and space (type an asterisk, followed by a colon); or more commonly, you can simply use a colon. Subsequent replies should be further indented using more colons; the number of colons provides a reference to the discussion level. For example, when you edit a talk page, the page source code may look like this:\n==sheep foraging habits== I was just wondering: what is the deal with the foraging habits of sheep? do the listed references cover this? I think we need some more detail about this important topic. -- Phoebe 19:11, 13 Jan 2007 (EST) :* Sheep foraging habits are covered in Sheep of the world, listed in references. -- Sj 18:24, 10 February 2007 (EST) ::* There's also some info in Sheep Past and Present.\u2014A New Zealander (talk) 18:55, 10 February 2007 (EST) :::* ok, thanks everyone! -- Phoebe 12:11, 11 Feb 2007 (EST)\nand will produce the page shown in Figure 4.5, \u201cA threaded discussion on a talk page\u201d.\nFigure 4.5. A threaded discussion on a talk page A threaded discussion on a talk page\nThis clearly shows the threaded discussion over time. A new topic is added to the bottom of the page with another section heading:\n==Wool== The paragraph about wool types is confusing. Could someone who understands the subject rewrite it? -- Charles Matthews 21:14, 14 Jan 2007 (EST)\nYou will see various styles of indentation used on Wikipedia.\nThe editor name and date are produced with automatic signatures. Comments on talk pages, unlike changes made to articles, should always be signed. To produce your signature, type four tildes (Phoebe (discuss \u2022 contribs) 04:40, 12 June 2013 (UTC)). If you're logged in, this will generate a signature that by default consists of your username with a link to your user page and a timestamp with the date and time of your edit. It looks something like this:\nUsername 19:36, 10 January 2006 (UTC)\nIf you're not logged in, typing four tildes will produce your IP address plus a timestamp. When adding talk page comments, it is certainly an advantage to have an account. It inspires some confidence in other editors to know your username\u2014you are identifying yourself as a member of the Wikipedia community, rather than just a number. With an account comes a user page and a personal user talk page, where people can, in turn, leave messages for you. If you aren't logged in, your IP address will be recorded; this address may be shared with other contributors if you are editing on a public computer, or it may change from edit to edit if it is a dynamic IP. IP addresses also have talk pages where messages can be left for that IP, but there is no guarantee that the message will reach the intended editor.\nTake Time to Tilde\nAlways sign comments on talk pages (but never sign articles)! This is one of the golden rules of Wikipedia; not doing so is considered very bad form. These days, if you don't sign your comments, a bot may give you a lesson in manners by adding your signature automatically when you leave talk page comments. Find out more about custom signatures in Chapter 11, Becoming a Wikipedian. 1.4.2. Making Good Use of Talk Pages\nOn talk pages, the basic idea is to make a clear point about how the article should be improved or what you'd like to know. For a suggested change, make a brief, calm case for your change (no need to go on at great lengths) backed up by necessary references. Chances are someone will change the article for you. If not, after a few days, you can do it yourself. Posting a preliminary comment on the talk page before making a change acts as a kind of insurance policy, as well as an explanation of your change. If you discuss first and then edit, you should not come under suspicion of high-handed behavior. Any controversial action should always be discussed on the talk page first. You are also welcome to weigh in on other ongoing discussions. In Chapter 12, Community and Communication, we'll take up how to use talk pages to communicate with other editors most effectively.\nUser talk pages are meant for conversation between editors, rather than conversation about a particular article. If you have an account, others may leave you messages on your user talk page by going to User talk:yourusername and editing the page there. When new messages are left for you on your user talk page, you'll receive a pop-up message when you next log in that notifies you about the messages (see Figure 4.6, \u201cA notice alerts you to a new message on your personal talk page.\u201d).\nFigure 4.6. A notice alerts you to a new message on your personal talk page. A notice alerts you to a new message on your personal talk page.\nThis notice makes it easy to know when you have new messages, and the prompt persists until you go to the page. If you're not logged in, you might still find a prompt and messages for your current IP number.\nYou can reply to any messages left for you on your own talk page, in a threaded discussion, or on the other editor's talk page. For more about how to conduct a good discussion with another editor on a user talk page, see Chapter 11, Becoming a Wikipedian. The basics are to be straightforward and, of course, polite.\nFurther Reading\n Discussion page guidelines\n Signing talk pages\nEvaluating Articles[edit | edit source]\nWikipedia is in a constant state of development, with contributors adding new articles and improving existing articles every minute. Inevitably, quality varies greatly from article to article. Although most articles in Wikipedia are useful as a basic reference, the majority are still incomplete treatments of their topic. Furthermore, some articles are unreliable, as discussed in this section; spotting these is the first concern of a careful reader. This unreliability does not make Wikipedia useless, but it does imply that you need to exercise a degree of caution.\nEvaluating articles is one of the fundamental skills for becoming both a skilled reader and an involved editor of Wikipedia. Whereas any reader should be able to judge the value of the information he or she is looking at quickly, editors must be able to discern what could be improved about an article as they set to work.\nWith experience, editors can quickly assess articles, even on unfamiliar topics, on the basis of clues and tricks of the trade. Although there are some established Wikipedia rating systems, judging articles remains more like choosing fresh produce rather than pulling processed food off a supermarket shelf\u2014it helps to know what you're looking for and how to judge blemishes. 2.1. Misinformation, Missing Information, and Mistakes\nMisinformation in an article is a real possibility, given the way that Wikipedia is compiled. The general public is, fortunately, now aware of this point: It is a very bad idea to rely on the uncorroborated testimony of a Wikipedia article. Use articles as stepping stones into a subject, not crutches to lean on. As it says at Wikipedia:General disclaimer, Wikipedia makes no guarantee of validity. A surprisingly common misconception is that Wikipedia employs fact-checkers for its articles, but that doesn't represent the situation on the ground. Facts are checked all the time by many active editors, but there is no one class of people on the site whose job is to confirm facts.\nIn most reference works, facts and other statements of truth are presented as having been vetted by a complex publishing process involving writers, editors, and fact-checkers, so the reader expects them to be correct. In Wikipedia, you cannot be so complacent. Though there are systems for peer review and developing accurate information, there is no guarantee at all that these processes and systems will have been applied to the particular article you're reading; the article might have been created in the past hour or not evaluated at all since it was created years ago. Each article is written by a different group of people with a varying amount of attention paid to it. Because of this, there is no serious way to judge Wikipedia as a whole; saying the site is a \"good source\" or a \"bad source\" is not precise enough. Instead, there are good and bad articles and a wide spectrum in between.\nThere are a few specific kinds of problems that may occur, each with different causes\u2014misinformation, missing information, and simple mistakes. They all lead to inaccurate information being presented to the reader.\nMisinformation, or bad information, comes in a few flavors. Wrong information that is purposely added is considered vandalism. Much of the vandalism on Wikipedia is obvious and silly graffiti or removal of article text in favor of graffiti. One of the great successes of Wikipedia is that this kind of vandalism can be easily cleaned up by anyone and is usually cleaned up very quickly; researchers that studied editing histories in 2003 measured the median cleanup time for obvious and vulgar vandalism as being less than three minutes.[20] Low-level vandalism, and its correction, is a constant occurrence in the open world of Wikipedia; a more recent study by University of Minnesota academics analyzed 57,601,644 article revisions and found that although about 5 percent of the revisions were vandalized, 42 percent of these damaged revisions were repaired essentially immediately, within one reader pageview.[21] (See Chapter 7, Cleanup, Projects, and Processes for more on vandal-fighting efforts).\nHowever, deliberately added misinformation or vandalism can also be quite subtle. Misinformation can be introduced deliberately by people attempting to get a point of view across (which violates Wikipedia's core policy of Neutral Point of View). This might be done by only including a certain side of a debate, adding in and emphasizing controversial views, or relying on sources that only promote a certain point of view. Convincing misinformation can persist for a long time, especially in little-trafficked articles, though a close eye on the article can usually reveal it as suspect when it was added. Much misinformation has a distinctive slanted tone that is out of character with the rest of the article and other properly written Wikipedia articles. The Taner Ak\u00e7am case involved misinformation that was both vandalism (malicious damage to site content) and defamatory (targeted at an individual's reputation).\nThe Problem with Misinformation\nA high-profile example of the problems that can result from not checking for vandalism occurred on February 16, 2007, when the Turkish scholar Taner Ak\u00e7am of the University of Minnesota was held up when traveling to Canada by border officials. Ak\u00e7am reported that, when pressed on why he was being detained, immigration officials showed him a copy of his Wikipedia article from December 24, 2006, which had been maliciously altered to claim he was a terrorist. The immigration officials had placed reliance on this misinformation. See Taner Ak\u00e7am for some links to the story and background on Ak\u00e7am's work on highly controversial issues.\nMuch more common than deliberate misinformation is the simple failure of missing information. Articles may be completely correct but missing key aspects of the topic. Further information and a more complete treatment could help put the topic better in context, or perhaps even totally change the meaning of the information in the article. Because Wikipedia is built piecemeal, for an article to be missing some information is extremely common\u2014and even expected. Stub articles, for instance, are known to be missing substantial details, but even longer or untagged articles may be missing parts. The only sure way to know you are getting the complete picture is to compare the article to other sources on the same topic.\nMistakes\u2014misinformation that is not added maliciously\u2014can happen in a wide variety of ways. Editors may add information that they remember to be true, but human memory is fallible. Perhaps they will add facts or ideas that have been discredited or are otherwise outdated. The sources that editors rely on might be wrong or misinterpreted. Copying and pasting information is very easy to do on the Web, so mistakes may be copied from one site to another and then repeated in Wikipedia (and then copied back out to other websites). Even simple typos, such as in numbers and dates, may lead to changes in meaning.\nWhat should you do when Wikipedia gives you wrong information? The important thing, perhaps, is not to rely on the site for crucial information; always check other sources in addition to Wikipedia for important topics. More fundamentally, however, evaluating the content that you find is important.\nIf a subject is unfamiliar to you, evaluating an article may turn out to be difficult as well as important. Fortunately, the transparency of Wikipedia's development process means there are a variety of places to look for problems. So far we have flagged clues\u2014any aspect of an article or its history where problems may be indicated if present. In this section, we'll outline a systematic approach, which should be applied more rigorously the more seriously you are studying a topic. A key theme is to look for clues to an author or authors' inexperience with Wikipedia.\nD-R-E-W-S[edit | edit source]\nThere are five general areas to evaluate for every article.\nD: Discussion Check the talk page of the article for any controversy regarding the article.\nR: Rating Is there a formal rating of the article, or a cleanup notice? WikiProject ratings are on talk pages, not in the article itself.\nE: Edit history The history of an article will tell you how and by whom it has been put together.\nW: Writing and format How does the page read? How does it look?\nS: Sources Are claims in the article well supported by solid references? 2.2.1. Discussion on the Talk Page\nA talk page may not yet exist for a given article (in which case it will show up in red), but for controversial topics, there are most likely some notices and discussion already there. A particular point that's bothering you may already have been discussed. Any warning tag appearing on the article referring to a content dispute should (though it doesn't always) also lead you to the appropriate discussion thread on the talk page.\nThe talk page is, therefore, where to start looking to see if the validity of the article content is disputed or other questions have been raised. Is there a long Table of Contents on the talk page? Are there links to archives of previous discussions? Both of these indicate involved debates in the past.\nIf you have your own concerns or questions about an article, the talk page is the place to post them. Anyone working on the article should notice these messages. 2.2.2. Ratings\nAnother aspect to consider is how articles have been rated by other editors. Ratings may be in the form of negative evaluations (such as cleanup tags on the article) or positive ones, as articles are assessed as being among the best in Wikipedia.\nThere are two formal rating processes to choose excellent articles, both of which involve getting consensus among editors. The lengthy peer review processes that produce featured articles and good articles do guarantee attention to quality. Featured articles, which may end up on the main page, represent some of the best content available; however, they make up only about 0.1 percent of the total content of Wikipedia. Once featured, an article will have a small bronze star in the upper-right corner along with a note indicating this on the discussion page. good articles, which do not need to be as extensive as featured articles, will only include a note on the talk page. (See Wikipedia:Featured articles and Wikipedia:Good articles to browse collections of these articles.)\nThere have also been several formal rating projects to assess the quality of articles within a certain topic area; these ratings typically don't require consensus but instead reflect an individual editor's opinion of the article, based on set standards. Most rating projects have been organized by WikiProjects that focus on a particular topic area (for instance, Wikipedia:WikiProject Chemistry, which was one of the first to rate articles). If you're using Wikipedia for research on a particular topic, you may be fortunate enough to find that basic article rating is well advanced in your area of interest. Most of the rating systems amount to saying, On a scale of 1 to 5, where is this article? Any rating notices will be placed on the article talk page.\nOne general assessment project is the Wikipedia 1.0 WikiProject, which has taken the idea of rating articles and applied it across topics in a drive to collect high-quality articles on basic topics for release in collections. (The project has already helped issue some CDs of basic Wikipedia content.) Wikipedia 1.0 uses six classifications to rate articles: stub, start, B, A, good article, and featured article (which is reserved for articles that have gone through the featured article process). This editorial classification is also adopted by some WikiProjects. Again, members of the 1.0 project leave their ratings on article talk pages.\nFinally, editors may assess articles as needing work. This is less formal than the processes just described, but is more widespread. As described, you may see warning messages at the tops of articles. These message boxes are produced by templates and may be added by any editor (as described in Chapter 7, Cleanup, Projects, and Processes), and if you see one, it's a clue to look closely to see what the problem is. Sometimes it's obvious: A completely unformatted article or one with terrible spelling and no wikilinks is likely to get a cleanup message. Sometimes it's not obvious, however, especially since templates don't automatically go away: Someone may fix the problem but fail to remove the template. One trick is to go through the page history to see when the message was added and if the edit summary gives any further information.\nIf you see a message noting that an article is up for deletion, this is a huge red flag that it's probably poor quality. The deletion message should give some short reason for deletion. Deletion decisions are made through one of several processes; often articles will be up for discussion for a period of time before the decision is made, and the message will link to this discussion. See Chapter 7, Cleanup, Projects, and Processes for more information.\nAll of these ratings are simply indicative and should be taken with a grain of salt\u2014ratings are approximate and subjective, often reflecting just one editor's assessment and not the current state of the article. However, knowing what other experienced editors think of the article can be extremely helpful in making your own decision about the article's quality.\nEdit History[edit | edit source]\nA wiki page, quite unlike most pieces of published writing, carries all its drafts along with it. One of the major benefits of keeping all versions is that investigative work can be carried out; you can track when a piece of information was inserted into an article and by whom. There are also a few bigger-picture things to consider when looking at an article history.\nWas the article recently created? When was it last edited?\nThough age is certainly no guarantee of quality, older articles have likely been seen and evaluated by more editors.\nHave many people contributed to the article, or is it the work of only one or two editors? Were those contributors logged in or editing anonymously?\nMore people working on an article should mean that more editors have seen, evaluated, and checked the article; however, minor edits such as spelling corrections probably don't indicate a full check of the article. If in doubt about a particular editor's change, check his or her overall contributions by clicking the Contribs link.\nIs there evidence of ongoing edit wars or arguments over content (that is, are there continual reversions of changes between two or more people)? Do the same changes keep getting made and undone, whether this is indicated in the edit summaries or not?\nThis may indicate a controversial topic, one on which there is no consensus, or an unverifiable topic. Verify any key facts with outside references. Serious edit wars tend to cause deterioration of the text, so also look at older versions of the page, which may be better than the current page. Not every edit war is over a serious matter: If the disagreement is niggling back and forth at some small point, does it matter to you?\nIs there evidence of heavy or continued vandalism (that is, constant changes and reversions, often between IP addresses and other editors, with edit summaries like revert or rvv vandalism)?\nAlthough this is not in itself evidence of quality problems\u2014some of the very best and most heavily trafficked articles on Wikipedia receive the most vandalism, simply because they are so visible\u2014it does mean you should make sure the article you are viewing is an unvandalized version. Some vandalism may be subtle, for instance, changing a date or a conclusion, and again it is best to verify important facts in outside sources. It's worth checking the differences between the version you're viewing and some previous versions that were edited by other people to make sure the version you're viewing is complete, not randomly cut by a vandal.\nIn general, for any article you are assessing, pick a few versions to compare to the current version. Get a sense of the page as dynamic: Has it changed a great deal over time, or was it submitted to the site nearly complete? How fast is the article changing? Was it once much longer than it is now? Although articles will generally get better and longer over time, sometimes they drift. Occasionally you will find that a previous version\u2014sometimes months or even years earlier\u2014was actually clearly better than the current version.\nWikipedia Brown and the Case of the Captured Koala: A Page History Mystery\nThis exciting online mystery by Adam Cadre hinges on reading a Wikipedia page history! See actual screenshots on Section 3.4.2, \u201cNavigating Categories\u201d at \nWriting and Formatting[edit | edit source]\nRead an article through, for example, as you would a newspaper article. In evaluating articles, you must, of course, consider the nature of the article text itself. First impressions of quality are significant. Is it properly presented and apparently comprehensive? Does it carry conviction, as to its authority and balance of coverage? These points matter, along with close reading for factual accuracy. However, there are more concrete clues to the level of an article's development, as well.\nIs the article well written, well explained, and in proper English? Within the article, is the topic explained in a way that makes sense to a casual reader, with a good explanatory opening paragraph and a clear definition in the first sentence?\nIf not, then it has likely lacked attention from experienced editors; it also may not have been written by someone really familiar with the topic. Good writing doesn't ensure factual accuracy, but as a piece of circumstantial evidence, it can make it more likely.\nOf course, we are not saying that an article written by a non-native speaker of English is necessarily worse than one written by a native speaker: Expertise outranks language skills. But if mistakes in English persist in an article, no editor on the site with good English has worked over it. What matters is the neglect, not who the first author was. If an article is well written in a tight factual style and properly organized, it was either originally written that way, or it was subsequently improved by other editors. Either way, the article was likely looked at by someone with a good knowledge of encyclopedic writing and Wikipedia conventions.\nIs the article formatted according to the Manual of Style? These are the guidelines for making Wikipedia articles look like Wikipedia articles.\nExperience shows that this question is also very useful, at least if you are familiar with standard format on Wikipedia pages. Chapter 6, Good Writing and Research describes the Wikipedia Manual of Style in some detail. Clue: Compliance with formatting guidelines means that the original author or subsequent editors were familiar with them. If you read Wikipedia for a while, it won't be hard to recognize a page that has obvious formatting problems.\nFor instance, is the page conventionally wikilinked to other Wikipedia articles? Are the See also and External links sections formatted as bulleted lists? Ask yourself, does the article look and read like a respectable article? A page with unconventional formatting or plenty of formatting mistakes probably was not written by an experienced editor, which means, in turn, that the author also may not have followed more fundamental content policies. Probably the article has also been neglected since it was first posted. It may also have been cut and pasted from another site (which is usually a copyright violation). They say you can't judge a book by its cover \u2026 but if the dust jacket had obvious typos, you might begin to wonder.\nNow you can assess the content itself.\nApparent Gaps\nSome format and sense issues can be clues to deletions by vandals. The removal of a chunk of text can on occasion be detected by missing punctuation, such as unfinished sentences, or other obvious glitches.\nAre there sections that explain various parts of the topic in more detail (such as History and Modern Status or Biography and Works)?\nArticles without sections tend to be unsorted, sometimes just collections of facts without much logical order. This could indicate work by an editor who is unfamiliar with Wikipedia, or perhaps there has been much editing without a comprehensive overview. If this is the case, expect some factual errors to have crept in. Take a look for gossip and rumor, urban myths, and so forth.\nDepending on the topic, do you see the elements that you would expect to be there?\nFor instance, an article about an author should include a formatted bibliography of works; an article about a historical event should place the event in context and provide some sort of chronology. The lack of these may not mean the article is poor but simply that it is incomplete, and other sources should also be used to get a complete picture.\nWhat tone does it take? Does it read like an encyclopedia article or like a personal essay or advertisement?\nIf an article clearly violates some of the core content policies, such as NPOV, then it was probably added by someone unfamiliar with Wikipedia, and it may or may not be suitable for the site. If there are outrageous claims in the midst of otherwise fair text, this may indicate vandalism and you should check back a few versions.\nSources[edit | edit source]\nIs the article referenced? This is a fairly simple but fundamental test of an article's quality. If you are troubled by other aspects, this is where you will be led to conclusions on trustworthiness.\nMany older encyclopedias do not list references in the text or at the end of an article. Instead, readers are expected to trust that the authors of those articles are experts in their field. The credibility of the work as a whole is an appeal to authority. In Wikipedia, there is really no way of knowing whether an article author is an expert or not. Instead, the references that are used matter greatly, both for verifying information and for giving you as a reader sources for further reading on the topic.\nA reference, in this context, refers to a citation to an outside work: for example, a printed article, book, or a web page. Other Wikipedia articles do not count as references; although these may be linked in the text or listed in the See also section, using them as sources is circular and misses the point of trying to get outside verification. (You might check those other articles to see if they are better sourced.)\nSources and references provide a very tangible way to evaluate an article's accuracy. You can (in principle) always go back and check the original sources yourself to find out what they say. Most people will first try the more indirect approach of quick plausibility checks on the Web. This is where searches excluding results from Wikipedia can be handy, as mentioned in Chapter 3, Finding Wikipedia's Content.\nThe best kind of reference is for a specific piece of information in the article to be footnoted appropriately, with the citation being specific as to where to find the relevant information. This is the inline referencing style. More than anything else, a footnoted reference to a page in a scholarly book should confer confidence in the footnoted statement's accuracy. If in doubt, always check what the cited source and other sources say.\nIn a fully referenced article, all specific facts should be referenced. There have been extensive debates in the Wikipedia community over what this means and how far to go with references. As a reader, you probably have priorities: Check references first for claims that are surprising or likely to prove contentious. That is, good references are most vital for statements that you are unlikely to just take the author's word on.\nMany articles are still not referenced inline. At the very least, sources should be clearly listed at the end of an article. Other references that are not used but that are relevant to studying the topic are placed in a Further reading section. Naturally, these references may still help you in verifying something.\n- Trivia Sections\nFrom the point of view of quality, it is hardest of all to assess isolated facts. A list of such facts with bullet points is a real challenge: How can one infer anything at all about the truth of any given point? This is precisely the state of trivia sections in many articles. If no reliable sources are given, there is no reason to trust them, since trivia may be surprising, obscure, or even bizarre. See Wikipedia:Avoid trivia sections in articles, shortcut WP:TRIVIA.\nThere are still hundreds of thousands of good, verifiable articles, contributed by experienced editors and about notable topics, that list no references. Referencing content is a slow and ongoing task, and strong emphasis was not placed on it during Wikipedia's early years. On the other hand, no references for a dubious topic may mean it's not suitable for inclusion in Wikipedia. The other evaluative criteria can help you tell which is the case. If it's a topic you know something about, adding good references is one of the key tasks that Wikipedia needs help with. Asking on talk pages is one basic way to request better referencing of a given article. Chapter 6, Good Writing and Research deals with techniques and syntax for referencing.\n- Further Reading\n The General disclaimer\n The criteria used by the Wikipedia 1.0 team\n An overview of considerations and techniques for using Wikipedia for research and evaluating individual articles\n An overview of the general reliability of Wikipedia\n[20] Vi\u00e9gas, Fernanda, et al. \"Studying Cooperation and Conflict Between Authors with History Flow Visualizations.\" (CHI 2004, April 24\u201329, 2004). The IBM History Flow project: \n[21] Priedhorsky, Reid, et al. \"Creating, Destroying, and Restoring Value in Wikipedia.\" (GROUP '07, November 4\u20137, 2007). \nSummary[edit | edit source]\nLook over the article text, its associated discussion page, and their histories. The reader aware of Wikipedia's editing process can use these related pages to understand the provenance of an article and evaluate it. This process of evaluation is mostly based on experience with Wikipedia's standards\u2014so if you're daunted by it, keep reading the site. Here is a baker's dozen of our best clues for evaluation, once more:\n- If no wikilinks exist in the text, there's a strong chance an article was written by someone unfamiliar with Wikipedia's conventions, and it may be questionable. Does the text comply with other content guidelines?\n- Compliance with Wikipedia formatting and style guidelines is a positive indication that an experienced editor has worked on the article. Are all the usual parts of an article present? Is it categorized in one or more categories?\n- Is the article a stub? Stubs will likely be incomplete in their information. Are there obvious aspects of the topic missing?\n- Did the material originally come from another source? Imported material, for example, from an old encyclopedia, may need updating.\n- No incoming links (backlinks) is often a sign that an article is new, has not been much scrutinized, or has a poor title. Check for duplicate articles on the topic with different titles. Is the topic verifiable in outside sources?\n- Is there evidence of disagreement or serious questions about content on the article discussion page?\n- Are there warning or cleanup messages at the top of the article? Has the article been rated by other editors?\n- A short page history is a warning sign. Is the article the work of more than one major author?\n- A patch of edits with reverts in a page history indicates some sort of editing war going on. The quality of articles is likely to degrade sharply in an extended edit war. Are earlier versions of the article better?\n- Are the authors new or experienced? Check their contributions\u2014what else have they been working on?\n- Especially for edits from an IP number, rather than an account, readers are entitled to treat edits without an edit summary with suspicion. Does the diff reveal vandalism or possible vandalism?\n- If you suspect vandalism, check the editor or IP's talk page; are there any warnings from other editors?\n- Are there sources present in the article? Are questionable or controversial statements referenced?",
        "transformed_text": "To proceed with your request, I need the specific text you want me to transform into a narrative, as well as the details for `{type_of_narrative}` and `{type_of_main_characters}`. Please provide these details so I can assist you effectively.",
        "type": "narration",
        "tag": []
    },
    {
        "original_text": "FreedomBox for Communities/Media Streaming\nStreaming of audio and video content for educational and entertainment purposes.\nA multimedia server hosted on FreedomBox hosts content which is streamed to client devices over the network. The free software server chosen for this purpose is Jellyfin, a fork of the now proprietary Emby media server.\nInstallation instructions[edit | edit source]\nJellyfin has an unofficial Debian package which can either be installed manually or from their repository. Install it onFreedomBox by following the instructions for Debian.\nSetting up Apache as reverse proxy[edit | edit source]\nCreate the file\n/etc/apache2/conf-available/ with the following contents.\n<Location /media> ProxyPass http://localhost:8096 </Location>\nNote: Do not set the path to /jellyfin as Jellyfin is served at /jellyfin by default. This would cause an infinite redirect.\nEnable the above Apache configuration by running the following commands.\nsudo ln -s /etc/apache2/conf-available/ /etc/apache2/conf-enabled sudo systemctl reload apache2\nNow the Jellyfin server should be available at https://<freedombox-url>/media",
        "transformed_text": "In the heart of a bustling digital forest, there lived a modest yet mighty server named FreedomBox. This server, a guardian of freedom and privacy, had a special purpose: to host a magical multimedia realm known as Jellyfin. Jellyfin, a spirited fork of the once-open Emby, was a server with a mission to stream audio and video content across the network, bringing joy and knowledge to all who sought it.\n\nJellyfin, with its unofficial Debian package, was a treasure waiting to be discovered. It could be installed either manually or through the mystical repository of Debian. Once summoned, it stood ready to serve its content to eager client devices scattered throughout the forest.\n\nTo enhance its reach, FreedomBox enlisted the help of Apache, a venerable reverse proxy. Apache, with its vast experience, created a pathway in the form of a configuration file, directing the flow of media through the enchanted location `/media`. This was a crucial step, for setting the path to `/jellyfin` would have led to an endless loop, a trap best avoided.\n\nWith the configuration enabled and Apache's blessing, Jellyfin was now accessible at the sacred URL `https://<freedombox-url>/media`. It was a gateway to a world of entertainment and education, a testament to the collaborative spirit of the digital realm.\n\nThus, FreedomBox and Jellyfin, with the aid of Apache, continued their quest to spread the magic of multimedia, ensuring that every device in the forest could partake in the wonders they offered.",
        "type": "narration",
        "tag": []
    }
]